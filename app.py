"""
app.py

Aplicaci칩n principal de Streamlit para el chatbot.
"""

import streamlit as st
from utils import load_model, generate_response

# 1. Configuraci칩n de la p치gina de Streamlit
st.set_page_config(page_title="Chatbot Open Source", page_icon="游눫", layout="centered")

# 2. T칤tulo y descripci칩n
st.title("Chatbot Open Source con Streamlit")
st.markdown("Este es un ejemplo de chatbot utilizando un modelo de lenguaje open source.")

# 3. Carga (en cach칠) del modelo
@st.cache_resource
def get_model():
    return load_model("phi")  # Usaremos el modelo phi de Ollama

model_name = get_model()

# 4. Manejo de estado de la conversaci칩n
if "conversation_history" not in st.session_state:
    st.session_state.conversation_history = []

# 5. Input de usuario
user_input = st.text_input("Escribe tu mensaje aqu칤:", "")

# 6. Bot칩n de env칤o
if st.button("Enviar") and user_input:  # Verificamos que haya input
    # A침adimos la entrada del usuario al historial
    st.session_state.conversation_history.append(f"Usuario: {user_input}")

    # Construimos un prompt m치s estructurado
    context = (
        "La siguiente es una conversaci칩n amigable y 칰til entre un humano y un asistente virtual.\n"
        "El asistente siempre responde en espa침ol de manera clara y precisa.\n\n"
        "\n".join(st.session_state.conversation_history[-3:]) +  # Solo usamos las 칰ltimas 3 interacciones
        "\nPregunta actual: " + user_input
    )
    
    # Generamos respuesta
    respuesta = generate_response(context, model_name)

    # Guardamos la respuesta en el historial
    st.session_state.conversation_history.append(f"Asistente: {respuesta}")

# 7. Mostrar el historial de conversaci칩n
if st.session_state.conversation_history:
    st.write("## Conversaci칩n")
    for line in st.session_state.conversation_history:
        if line.startswith("Usuario:"):
            st.markdown(f"**{line}**")
        else:
            st.markdown(line)
